{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import semantique as sq\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a mapping.\n",
    "with open(\"../files/mapping.json\", \"r\") as file:\n",
    "    mapping = sq.mapping.Semantique(json.load(file))\n",
    "\n",
    "# Represent an EO data cube.\n",
    "with open(\"../files/layout_gtiff.json\", \"r\") as file:\n",
    "    dc = sq.datacube.GeotiffArchive(json.load(file), src = \"../files/layers_gtiff.zip\")\n",
    "\n",
    "# Set the spatio-temporal extent.\n",
    "space = sq.SpatialExtent(gpd.read_file(\"../files/footprint.geojson\"))\n",
    "time = sq.TemporalExtent(\"2019-01-01\", \"2020-12-31\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the cache works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caching data layers in RAM should only be done for those that are needed again when evaluating downstream parts of the recipe. This requires foresight about the execution order of the recipe, which accordingly requires a simulated run preceding the actual execution. This simulated run is performed by the FakeProcessor. It resolves the data references and fills a cache by creating a list of the data references in the order in which they are evaluated. This list is then used dynamically during the actual execution of the recipe as a basis for keeping data layers in the cache and reading them from there if they are needed again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantique.processor.core import FakeProcessor, QueryProcessor\n",
    "\n",
    "# define a simple recipe for a cloudfree composite\n",
    "recipe = sq.QueryRecipe()\n",
    "red_band = sq.reflectance(\"s2_band04\")\n",
    "green_band = sq.reflectance(\"s2_band03\")\n",
    "blue_band = sq.reflectance(\"s2_band02\")\n",
    "recipe[\"composite\"] = sq.collection(red_band, green_band, blue_band).\\\n",
    "    filter(sq.entity(\"cloud\").evaluate(\"not\")).\\\n",
    "    reduce(\"median\", \"time\").\\\n",
    "    concatenate(\"band\")\n",
    "\n",
    "# define context \n",
    "context = {\n",
    "    \"datacube\": dc, \n",
    "    \"mapping\": mapping,\n",
    "    \"space\": space,\n",
    "    \"time\": time,\n",
    "    \"crs\": 3035, \n",
    "    \"tz\": \"UTC\", \n",
    "    \"spatial_resolution\": [-10, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reflectance', 's2_band04'),\n",
       " ('reflectance', 's2_band03'),\n",
       " ('reflectance', 's2_band02'),\n",
       " ['atmosphere', 'colortype']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step I: fake run\n",
    "fp = FakeProcessor.parse(recipe, **context)\n",
    "fp.optimize().execute()\n",
    "fp.cache.seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 563, 576)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step II: query processor execution\n",
    "qp = QueryProcessor.parse(recipe, **{**context, \"cache\": fp.cache})\n",
    "result = qp.optimize().execute()\n",
    "result[\"composite\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the FakeProcessor run resolves the references to the data layers as they are provided by looking up the entities' references in the mapping.json. Note, that in the current case the result is not that interesting, though, since four different data layers are to be loaded. Therefore, there is nothing to be cached during recipe execution. Therefore the QueryProcessor will load all data layers from the referenced sources without storing any of them in the cache. \n",
    "\n",
    "As a user, however, you can directly initiate the entire caching workflow (preview & full resolution recipe execution) by setting the context parameter when calling `recipe.execute(..., cache_data = True)`. This is enabled by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above in a single step \n",
    "result = recipe.execute(**{**context, \"cache_data\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment of cache performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's analyse some timing differences in executing a recipe with/without caching. Most importantly, the timing difference depends on...\n",
    "* the redundancy of the data references in the recipe, i.e. if layers are called multiple times loading them from cache will reduce the overall time significantly\n",
    "* the data source (EO data cube) from which they are loaded\n",
    "\n",
    "Especially for the later it should be noted that in this demo only data loaded from a locally stored geotiff (i.e. the GeoTiffArchive layout) are analysed. This is sort of the worst case for demonstrating the benefits of caching since the data is stored locally and is therfore quickly accessible.\n",
    "\n",
    "Consequently, you will observe that in almost all of the following cases, caching actually adds a small computational overhead. Keep in mind, however, that caching is designed for and particularly beneficial in case of STACCubes when loading data over the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compare timing for given recipe \n",
    "def eval_timing(recipe, caching=False):\n",
    "    context = {\n",
    "        \"datacube\": dc, \n",
    "        \"mapping\": mapping,\n",
    "        \"space\": space,\n",
    "        \"time\": time,\n",
    "        \"crs\": 3035, \n",
    "        \"tz\": \"UTC\", \n",
    "        \"spatial_resolution\": [-10, 10],\n",
    "        \"cache_data\": caching\n",
    "    }\n",
    "    res = recipe.execute(**context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe I\n",
    "recipe_I = sq.QueryRecipe()\n",
    "red_band = sq.reflectance(\"s2_band04\")\n",
    "green_band = sq.reflectance(\"s2_band03\")\n",
    "blue_band = sq.reflectance(\"s2_band02\")\n",
    "recipe_I[\"composite\"] = sq.collection(red_band, green_band, blue_band).\\\n",
    "    filter(sq.entity(\"cloud\").evaluate(\"not\")).\\\n",
    "    reduce(\"median\", \"time\").\\\n",
    "    concatenate(\"band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 ms ± 3.41 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# without caching\n",
    "_ = eval_timing(recipe_I, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703 ms ± 18.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# with caching\n",
    "_ = eval_timing(recipe_I, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe II\n",
    "recipe_II = sq.QueryRecipe()\n",
    "recipe_II[\"dates\"] = sq.entity(\"vegetation\").\\\n",
    "    filter(sq.self()).\\\n",
    "    assign_time().\\\n",
    "    reduce(\"first\", \"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.28 s ± 72.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# without caching\n",
    "_ = eval_timing(recipe_II, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.51 s ± 106 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# with caching\n",
    "_ = eval_timing(recipe_II, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe III\n",
    "recipe_III = sq.QueryRecipe()\n",
    "recipe_III[\"water_count_time\"] = sq.entity(\"water\").reduce(\"count\", \"time\")\n",
    "recipe_III[\"vegetation_count_time\"] = sq.entity(\"vegetation\").reduce(\"count\", \"time\")\n",
    "recipe_III[\"water_count_space\"] = sq.entity(\"water\").reduce(\"count\", \"space\")\n",
    "recipe_III[\"vegetation_count_space\"] = sq.entity(\"vegetation\").reduce(\"count\", \"space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495 ms ± 7.52 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# without caching\n",
    "_ = eval_timing(recipe_III, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283 ms ± 1.64 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# with caching\n",
    "_ = eval_timing(recipe_III, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more expressive examples for the STACCube are provided below. The question if caching brings significant advantages when loading data from a well-indexed OpenDataCube stored on a quickly accessible hot storage, remains to be assessed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
